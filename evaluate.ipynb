{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "550cba74-b156-4989-8305-e5854c509515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from peewee import SqliteDatabase\n",
    "import msgspec\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e35c8e9a-e314-4479-92ee-808179a5d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import get_model_class\n",
    "from data_schema import SentencePair\n",
    "from load_spacy import load_spacy, translate_sequence\n",
    "from sentence_embedding_model_v7 import SentenceEmbeddingV7\n",
    "from train_sentence_embedding import CFG, dataset_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c354e091-d898-4421-bf25-03c584f933a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfae526-2733-42fd-9206-78b881163768",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load_spacy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8644946d-ca15-496f-9cb3-45f28daa3c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceEmbeddingV7(\n",
       "  (compress1): Linear(in_features=300, out_features=256, bias=False)\n",
       "  (compress2): Linear(in_features=256, out_features=128, bias=False)\n",
       "  (compress3): Linear(in_features=128, out_features=64, bias=False)\n",
       "  (compress_norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (encoder1): GRU(64, 16, num_layers=5)\n",
       "  (decode2): GRU(16, 16, num_layers=4, dropout=0.89)\n",
       "  (linear_out1): Linear(in_features=16, out_features=128, bias=False)\n",
       "  (linear_out2): Linear(in_features=16, out_features=128, bias=False)\n",
       "  (linear_out3): Linear(in_features=16, out_features=128, bias=False)\n",
       "  (linear_out4): Linear(in_features=16, out_features=128, bias=False)\n",
       "  (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.89, inplace=False)\n",
       "  (cos): CosineSimilarity()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = 'tmp/checkpoints/v9/epoch100_encoder1'\n",
    "\n",
    "CFG['device'] = device\n",
    "\n",
    "encoder1 = SentenceEmbeddingV7(config=CFG, nlp=nlp, batch_size=BATCH_SIZE).to(device)\n",
    "encoder1.load_state_dict(torch.load(checkpoint))\n",
    "encoder1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfe0e3c0-715c-4648-b990-9a7110816845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'guardian_headlines'\n",
    "\n",
    "db = SqliteDatabase(f'sentence_embedding_training_data/{dataset}.txt.db')\n",
    "ModelClass = get_model_class(db)\n",
    "db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9079788c-226d-4ebe-96ff-6f03c416e1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample1:  [141171, 289, 18, 487, 186, 539, 5, 6076, 105, 931, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157]\n",
      "sample1_ts.shape:  torch.Size([40, 300])\n",
      "sample1_ts:  tensor([-0.1264, -2.5252,  2.0018,  0.7056,  2.4124], device='cuda:0')\n",
      "sample1_ts:  tensor([ 1.6989,  5.3603, -0.2236,  1.3875,  4.8625], device='cuda:0')\n",
      "sample1_ts:  tensor([ 6.5268,  9.8299, -4.6809, -1.7518,  1.8730], device='cuda:0')\n",
      "input1.shape:  torch.Size([40, 2, 300])\n",
      "input.shape:  torch.Size([40, 2, 300])\n",
      "compressed:  [1.4100443124771118, -1.8930031061172485, -0.7354149222373962, 0.7657529711723328, -0.6652577519416809]\n",
      "compressed:  [0.7302178144454956, -0.10998714715242386, -0.36964771151542664, 0.4085789918899536, -0.44284600019454956]\n",
      "compressed:  [-12.233009338378906, 8.465375900268555, 9.533697128295898, -9.571235656738281, 8.64380168914795]\n",
      "encoded_1:  [0.5431398749351501, 0.6603038907051086, 0.8267356157302856, 0.001467584865167737, 0.08686985820531845]\n",
      "encoded_1:  [0.5831382870674133, 0.8088379502296448, 0.9195440411567688, -0.11457901448011398, -0.19764818251132965]\n",
      "encoded_1:  [0.6004681587219238, -0.6543844938278198, 0.942861020565033, -0.1420735865831375, -0.7428264021873474]\n",
      "encoded_hidden_1:  [-0.9945154190063477, 0.9382577538490295, -0.4416238069534302, -0.9991204142570496, 0.9933616518974304]\n",
      "encoded_hidden_1:  [0.8478094339370728, 0.7901691198348999, 0.9287862777709961, 0.9682081937789917, 0.9968104362487793]\n",
      "encoded_hidden_1:  [0.9752369523048401, -0.9912446141242981, 0.9756702184677124, -0.05478866025805473, -0.9771901369094849]\n",
      "sample2:  [211, 51, 3, 6572, 876, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157, 514157]\n",
      "sample2_ts:  tensor([-3.8156, -6.8896, -0.1516,  1.3017,  4.7588], device='cuda:0')\n",
      "sample2_ts:  tensor([-2.0123, -1.9737, -0.2872,  0.2060,  0.9696], device='cuda:0')\n",
      "sample2_ts:  tensor([-5.1043,  2.3496,  3.2472,  2.8424, 11.4590], device='cuda:0')\n",
      "input2.shape:  torch.Size([40, 2, 300])\n",
      "input.shape:  torch.Size([40, 2, 300])\n",
      "compressed:  [-6.231078147888184, 2.5143396854400635, 5.184399604797363, -5.197189807891846, 4.78373908996582]\n",
      "compressed:  [-6.938246726989746, 3.59547758102417, 5.656520366668701, -5.672026634216309, 5.160799026489258]\n",
      "compressed:  [4.011666774749756, -7.777478218078613, -2.29672908782959, 2.2766733169555664, -1.7032138109207153]\n",
      "encoded_1:  [-0.029283620417118073, 0.6310276389122009, 0.9546628594398499, -0.12322892993688583, 0.1129365861415863]\n",
      "encoded_1:  [0.10731162875890732, 0.8611937165260315, 0.9450185298919678, -0.2664624750614166, -0.09750696271657944]\n",
      "encoded_1:  [0.16090494394302368, -0.5271181464195251, 0.9512552618980408, -0.2917565703392029, -0.7015790939331055]\n",
      "encoded_hidden_1:  [-0.9965373873710632, 0.9545919299125671, -0.7520747184753418, -0.9992616176605225, 0.9949011206626892]\n",
      "encoded_hidden_1:  [0.8790401220321655, 0.8200408816337585, 0.9275228381156921, 0.9682018160820007, 0.9966520667076111]\n",
      "encoded_hidden_1:  [0.9614049792289734, -0.9913653135299683, 0.9733878970146179, -0.17851142585277557, -0.9777984619140625]\n",
      "Centrica left it far too late to tackle its problems - For all the brave words - score: 0.9997069835662842\n",
      "Centrica left it far too late to tackle its problems - For all the brave words - score: 0.9996267557144165\n"
     ]
    }
   ],
   "source": [
    "word_embedding= encoder1.get_word_embedding()\n",
    "\n",
    "counter = 0\n",
    "iteration = 2\n",
    "\n",
    "for record in ModelClass.select():\n",
    "    counter += 1\n",
    "\n",
    "    if counter == 1:\n",
    "        continue\n",
    "        \n",
    "    pair = msgspec.json.decode(record.json_data, type=SentencePair)\n",
    "    sample1 = pair.sample1\n",
    "    print('sample1: ', sample1)\n",
    "    text1 = translate_sequence(sample1, nlp)\n",
    "    sample1_ts = torch.from_numpy(np.array(sample1)).to(device)\n",
    "    sample1_ts = word_embedding(sample1_ts)\n",
    "    # sample1_ts = sample1_ts.unsqueeze(dim=1)\n",
    "    print('sample1_ts.shape: ', sample1_ts.shape)\n",
    "    print('sample1_ts: ', sample1_ts[0][0:5])\n",
    "    print('sample1_ts: ', sample1_ts[1][0:5])\n",
    "    print('sample1_ts: ', sample1_ts[2][0:5])\n",
    "    input1 = torch.stack((sample1_ts, sample1_ts), dim=1)\n",
    "    print('input1.shape: ', input1.shape)\n",
    "    embedded1 = encoder1(input1)\n",
    "\n",
    "    sample2 = pair.sample2\n",
    "    print('sample2: ', sample2)\n",
    "    text2 = translate_sequence(sample2, nlp)\n",
    "    sample2_ts = torch.from_numpy(np.array(sample2)).to(device)\n",
    "    sample2_ts = word_embedding(sample2_ts)\n",
    "    # sample2_ts = sample2_ts.unsqueeze(dim=1)\n",
    "    print('sample2_ts: ', sample2_ts[0][0:5])\n",
    "    print('sample2_ts: ', sample2_ts[1][0:5])\n",
    "    print('sample2_ts: ', sample2_ts[2][0:5])\n",
    "    input2 = torch.stack((sample2_ts, sample2_ts), dim=1)\n",
    "    print('input2.shape: ', input2.shape)\n",
    "    embedded2 = encoder1(input2)\n",
    "\n",
    "    score = encoder1.cos(embedded1, embedded2)\n",
    "\n",
    "    print(f'{text1} - {text2} - score: {score[0].item()}')\n",
    "    print(f'{text1} - {text2} - score: {score[1].item()}')\n",
    "\n",
    "    if counter >= iteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e92e131-83f9-4aba-9eec-0623e2821ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
